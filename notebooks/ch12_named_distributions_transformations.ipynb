{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860493c0",
   "metadata": {},
   "source": [
    "<img src='https://theaiengineer.dev/tae_logo_gw_flat.png' alt='The Python Quants' width='35%' align='right'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b93b612",
   "metadata": {},
   "source": [
    "# Python & Mathematics for Data Science and Machine Learning\n",
    "\n",
    "**© Dr. Yves J. Hilpisch | The Python Quants GmbH**<br>\n",
    "AI-powered by GPT-5.x.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdde4ad",
   "metadata": {},
   "source": [
    "# Chapter 12 — Named Distributions & Transformations\n",
    "\n",
    "Work with SciPy distribution objects, compare empirical vs analytic moments, and apply log-sum-exp stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39be0c5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up imports and basic configuration.\n"
   ],
   "id": "b1a74e23ff5e45fba17f5530c70d10c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6ad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np  # numerical arrays and linear algebra\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "from scipy import stats\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "rng = np.random.default_rng(1)  # reproducible random generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7206edfe",
   "metadata": {},
   "source": [
    "## Moments for named distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48584bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_specs = {\n",
    "    'normal': stats.norm(loc=0.0, scale=1.0),\n",
    "    'poisson': stats.poisson(mu=3.0),\n",
    "    'exponential': stats.expon(scale=0.5),\n",
    "    'beta': stats.beta(a=2.0, b=5.0),\n",
    "}\n",
    "\n",
    "for name, dist in dist_specs.items():\n",
    "    samples = dist.rvs(size=40_000, random_state=rng).astype(np.float64)\n",
    "    mean_emp = samples.mean()\n",
    "    var_emp = samples.var(ddof=1)\n",
    "    print(\n",
    "        f\"{name:10s} mean: {mean_emp:.3f} vs {dist.mean():.3f}\",\n",
    "        f\"  var: {var_emp:.3f} vs {dist.var():.3f}\"\n",
    "    )  # report results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afacbed",
   "metadata": {},
   "source": [
    "## Stable log-sum-exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function for clarity.\n"
   ],
   "id": "188af5be16d942ba9f46ff92d8d6a39f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a9340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp_naive(arr):  # function logsumexp_naive\n",
    "    return np.log(np.sum(np.exp(arr)))\n",
    "\n",
    "def logsumexp_stable(arr):  # function logsumexp_stable\n",
    "    m = np.max(arr)\n",
    "    return m + np.log(np.sum(np.exp(arr - m)))\n",
    "\n",
    "log_probs = np.array([-120.0, -122.0, -119.5], dtype=np.float64)\n",
    "print('naive:', logsumexp_naive(log_probs))  # report results\n",
    "print('stable:', logsumexp_stable(log_probs))  # report results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5872a3d",
   "metadata": {},
   "source": [
    "## Quantile transform to Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4f3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_dist = stats.gamma(a=3.0, scale=2.0)\n",
    "uniform_draws = rng.random(100_000)\n",
    "gamma_samples = gamma_dist.ppf(uniform_draws)\n",
    "ks_stat, ks_p = stats.kstest(gamma_samples, gamma_dist.cdf)\n",
    "print(\n",
    "    f\"KS p-value={ks_p:.3f}\",\n",
    "    f\"  empirical mean={gamma_samples.mean():.3f}\",\n",
    "    f\"  theory={gamma_dist.mean():.3f}\"\n",
    ")  # report result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edb5e8d",
   "metadata": {},
   "source": [
    "## Distribution gallery (continuous vs discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e89e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-4, 4, 400)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(\n",
    "    x,\n",
    "    stats.gamma(a=2.0, scale=1.0).pdf(x.clip(min=0)),\n",
    "    label='Gamma(2, 1)',\n",
    "    lw=2.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710c49aa",
   "metadata": {},
   "source": [
    "---\n",
    "Named distributions become practical once you can simulate, evaluate, and stabilise their likelihoods in code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://theaiengineer.dev/tae_logo_gw_flat.png' alt='The Python Quants' width='35%' align='right'>\n"
   ],
   "id": "9c6d8da41237486492fda217ac04d9e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}