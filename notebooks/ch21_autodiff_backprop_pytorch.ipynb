{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"right\">\n",
    "  <img src=\"https://hilpisch.com/tpq_logo.png\" alt=\"The Python Quants\" width=\"35%\" />\n",
    "</p>\n"
   ],
   "id": "9f469a6d256342ca85b644c158a8b2f5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python & Mathematics for Data Science and Machine Learning\n\n",
    "(c) Dr. Yves J. Hilpisch | The Python Quants GmbH\n\n",
    "AI-powered by GPT-5\n"
   ],
   "id": "8f390cc06a4347ceb280a967cb4d7952"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 21 — Autodiff, Backprop, and What PyTorch Automates\n\n",
    "Tiny reverse‑mode autodiff and checks vs finite differences.\n"
   ],
   "id": "be76af5e407149b8a20fbd8a5206026c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ],
   "id": "8fadb83c868848e580c80252fb57692e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8')\n"
   ],
   "id": "f22265b6273945f987502d45345bc014"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiny reverse-mode engine + gradcheck"
   ],
   "id": "c5a51febd34145af811b8616ef9d76cc"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np  # arrays and math\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, value, parents=(), backward=lambda g: None, name=None):\n",
    "        self.value = np.asarray(value, dtype=float)\n",
    "        self.parents = parents\n",
    "        self.backward_fn = backward\n",
    "        self.grad = np.zeros_like(self.value)\n",
    "        self.name = name\n",
    "\n",
    "    def backward(self, grad=None):\n",
    "        topo = []\n",
    "        seen = set()\n",
    "        def build(v):\n",
    "            if id(v) in seen:\n",
    "                return\n",
    "            seen.add(id(v))\n",
    "            for p in v.parents:\n",
    "                build(p)\n",
    "            topo.append(v)\n",
    "        build(self)\n",
    "        self.grad[...] = 1.0 if grad is None else grad\n",
    "        for v in reversed(topo):\n",
    "            v.backward_fn(v.grad)\n",
    "\n",
    "# Primitives (each returns a Node with value and backward rule)\n",
    "def add(a, b):\n",
    "    a = a if isinstance(a, Node) else Node(a)\n",
    "    b = b if isinstance(b, Node) else Node(b)\n",
    "    z = Node(a.value + b.value, parents=(a, b))\n",
    "    def backward(g):\n",
    "        a.grad += g\n",
    "        b.grad += g\n",
    "    z.backward_fn = backward\n",
    "    return z\n",
    "\n",
    "def mul(a, b):\n",
    "    a = a if isinstance(a, Node) else Node(a)\n",
    "    b = b if isinstance(b, Node) else Node(b)\n",
    "    z = Node(a.value * b.value, parents=(a, b))\n",
    "    def backward(g):\n",
    "        a.grad += g * b.value\n",
    "        b.grad += g * a.value\n",
    "    z.backward_fn = backward\n",
    "    return z\n",
    "\n",
    "def tanh(a):\n",
    "    a = a if isinstance(a, Node) else Node(a)\n",
    "    t = np.tanh(a.value)\n",
    "    z = Node(t, parents=(a,))\n",
    "    def backward(g):\n",
    "        a.grad += g * (1.0 - t * t)\n",
    "    z.backward_fn = backward\n",
    "    return z\n",
    "\n",
    "def sum1(a):\n",
    "    a = a if isinstance(a, Node) else Node(a)\n",
    "    z = Node(np.array(a.value.sum()), parents=(a,))\n",
    "    def backward(g):\n",
    "        a.grad += g\n",
    "    z.backward_fn = backward\n",
    "    return z\n",
    "\n",
    "# Toy network and grad check\n",
    "rs = np.random.default_rng(21)\n",
    "x = Node(rs.normal())\n",
    "w1 = Node(rs.normal())\n",
    "b1 = Node(0.0)\n",
    "w2 = Node(rs.normal())\n",
    "b2 = Node(0.0)\n",
    "y = Node(1.0)\n",
    "\n",
    "a1 = add(mul(w1, x), b1)\n",
    "h = tanh(a1)\n",
    "yhat = add(mul(w2, h), b2)\n",
    "loss = sum1((yhat.value - y.value) ** 2)\n",
    "loss.parents = (yhat, y)\n",
    "\n",
    "def back(g):\n",
    "    yhat.grad += g * 2.0 * (yhat.value - y.value)\n",
    "    y.grad += g * -2.0 * (yhat.value - y.value)\n",
    "\n",
    "loss.backward_fn = back\n",
    "loss.backward()\n",
    "print('grads', float(w1.grad), float(w2.grad))\n"
   ],
   "id": "8130b7456df04c22a914a62939fd1c98"
  }
 ]
}