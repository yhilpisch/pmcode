{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://theaiengineer.dev/tae_logo_gw_flat.png' alt='The Python Quants' width='35%' align='right'>\n"
   ],
   "id": "c5bb7b8b85e3454cb391de3470c85f70"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python & Mathematics for Data Science and Machine Learning\n",
    "\n",
    "**© Dr. Yves J. Hilpisch | The Python Quants GmbH**<br>\n",
    "AI-powered by GPT-5.x.\n",
    "\n"
   ],
   "id": "1568a341f3f64b6587242ecab4eb133a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2 — Python Essentials (Math‑Centric)\n\n",
    "This notebook mirrors the second chapter. It focuses on float behavior, shapes, views vs copies, and vectorization patterns that make math transparent and reliable in code."
   ],
   "id": "6bbae637d1aa4dc881d48dd766412c6e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up imports and basic configuration.\n"
   ],
   "id": "8fe19e7e13f846beb351713755febc68"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np  # numerical arrays and linear algebra\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "from decimal import Decimal, getcontext\n",
    "plt.style.use('seaborn-v0_8')\n",
    "rs = np.random.default_rng(42)  # reproducible random generator\n",
    "getcontext().prec = 60  # high precision for references\n"
   ],
   "id": "b3f4d12e71c246a19717fe207b1cce4a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Float64 epsilon and unit roundoff\n\n",
    "We compare NumPy's epsilon with half the ULP for binary64."
   ],
   "id": "58a39fb7cc48433ba8d2e19c1c32ac85"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine epsilon (gap between 1 and next float64) and unit roundoff (half)\n",
    "np.finfo(np.float64).eps, 0.5 * 2.0**-52\n"
   ],
   "id": "7e3f8b4567cf437dbf4eb37f13a426d3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 + 0.2 != 0.3 (float64) vs Decimal truth\n\n",
    "Binary floating-point cannot exactly represent 0.1 and 0.2; Decimal with sufficient precision can."
   ],
   "id": "5d819459fecd491d8dcb3f9477e748d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1 + 0.2 == 0.3, Decimal('0.1') + Decimal('0.2') == Decimal('0.3')\n"
   ],
   "id": "ea14c596cda54ea9b4da866725f3ee67"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Views vs copies and shapes\n\n",
    "Slicing returns a view; fancy indexing returns a copy (often changing shape)."
   ],
   "id": "4d02a9aa5fbc40d0aeca1ad561558e47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(6, dtype=np.float64).reshape(2, 3)\n",
    "v = a[:, 1]           # view (slice)\n",
    "c = a[:, [1]]         # copy (fancy index makes shape (2,1))\n",
    "v[0] = 999.\n",
    "a, v, c, np.shares_memory(a, v), np.shares_memory(a, c)\n"
   ],
   "id": "5a4cbb2710b94163931c361b935a13bb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting and einsum clarity\n\n",
    "We express the same linear map with @ and with einsum to make index roles explicit."
   ],
   "id": "0d8ca71238ee49809031d832ada59465"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1., 2., 3.], [4., 5., 6.]])  # (2,3)\n",
    "x = np.array([0.5, 1.0, -1.0])              # (3,)\n",
    "y1 = A @ x\n",
    "# Same result via einsum with explicit index roles: i = sum_j A_ij x_j\n",
    "y2 = np.einsum('ij,j->i', A, x)\n",
    "y1, y2, np.allclose(y1, y2)\n"
   ],
   "id": "6947679f3f814a8da7441228f02012da"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Floating-point is not associative\n\n",
    "We show a classic counterexample where ordering changes the result due to rounding."
   ],
   "id": "fa6aa099c8a3437d99d1d6394a0b1632"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = 1e16, 1.0, -1e16\n",
    "(x + y) + z, x + (y + z)\n"
   ],
   "id": "c3f264598fce486bafd4bf96f86e2ae0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: rounding error in summation (naive vs Kahan)\n\n",
    "We compare absolute error vs a high-precision reference for naive running sum and Kahan compensated summation on many tiny positives."
   ],
   "id": "605ef3778e704cd88778328612e61941"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function for clarity.\n"
   ],
   "id": "79eb0f0c4e164a6cac0ba00ae22174b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kahan_sum(arr: np.ndarray) -> np.ndarray:  # function kahan_sum\n",
    "    s = 0.0\n",
    "    c = 0.0\n",
    "    out = np.empty_like(arr, dtype=np.float64)\n",
    "    for i, x in enumerate(arr):\n",
    "        y = x - c\n",
    "        t = s + y\n",
    "        c = (t - s) - y\n",
    "        s = t\n",
    "        out[i] = s\n",
    "    return out\n",
    "\n",
    "n = 20000\n",
    "a = rs.uniform(0, 1e-10, size=n).astype(np.float64)\n",
    "\n",
    "# High-precision reference prefix sums\n",
    "pref = []\n",
    "acc = Decimal(0)\n",
    "for x_ in a:\n",
    "    acc += Decimal(str(x_))  # preserve decimal digits\n",
    "    pref.append(acc)\n",
    "ref = np.array([float(v) for v in pref], dtype=np.float64)\n",
    "\n",
    "naive = np.cumsum(a)\n",
    "kahan = kahan_sum(a)\n",
    "\n",
    "err_naive = np.abs(naive - ref)\n",
    "err_kahan = np.abs(kahan - ref)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.8, 3.6), dpi=140)\n",
    "x_ix = np.arange(1, n + 1)\n",
    "ax.plot(x_ix, err_naive, label='naive cumsum', color='C1', lw=1.4)  # plot element\n",
    "ax.plot(x_ix, err_kahan, label='Kahan sum', color='C2', lw=1.4)  # plot element\n",
    "ax.set_xscale('log')  # set axis/scale\n",
    "ax.set_yscale('log')  # set axis/scale\n",
    "ax.set_xlabel('n (log scale)')  # set axis/scale\n",
    "ax.set_ylabel('absolute error (log scale)')  # set axis/scale\n",
    "ax.set_title('Rounding error in summation: naive vs Kahan')  # set axis/scale\n",
    "ax.legend()  # plot element\n",
    "ax.grid(alpha=0.25)  # plot element\n",
    "plt.show()  # render figure\n"
   ],
   "id": "249e8d53a08a472495d7d5f05720c0a0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n\n",
    "- Error growth: naive summation’s rounding error accumulates with n.\n",
    "- Compensation helps: Kahan recovers low-order bits and lowers error.\n",
    "- Scaling matters: smaller terms relative to the running total suffer more rounding; summing small first helps.\n"
   ],
   "id": "f24083ab85f64f4a8a8fdda7f694ed3d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underflow/overflow and stable transforms\n\n",
    "We show overflow in exp and fix softplus/log-sum-exp with stable formulations."
   ],
   "id": "b155247d91c0419ebab76f3f52698f92"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up imports and basic configuration.\n"
   ],
   "id": "6b2e99590dad4e0ca68be57bf0140f0f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np  # numerical arrays and linear algebra\n",
    "def softplus_naive(x):  # function softplus_naive\n",
    "    return np.log1p(np.exp(x))\n",
    "def softplus_stable(x):  # numerically stable implementation\n",
    "    x = np.asarray(x, dtype=np.float64)\n",
    "    pos = x > 0\n",
    "    y = np.empty_like(x)\n",
    "    y[pos]  = x[pos] + np.log1p(np.exp(-x[pos]))\n",
    "    y[~pos] = np.log1p(np.exp(x[~pos]))\n",
    "    return y\n",
    "xs = np.array([-1000., -50., -1., 0., 1., 50., 1000.])\n",
    "np.exp(1000), softplus_naive(xs), softplus_stable(xs)\n"
   ],
   "id": "add78ffd9a634ad8aa39585d5f9e0b16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1000., 999., 995.])\n",
    "m = a.max()\n",
    "naive = np.log(np.sum(np.exp(a)))\n",
    "stable = m + np.log(np.sum(np.exp(a - m)))\n",
    "naive, stable\n"
   ],
   "id": "917034b1c9ba4528b9623eba41f24a83"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## math vs numpy and broadcasting\n\n",
    "Compare scalar math functions to vectorized NumPy and a broadcasting distance matrix."
   ],
   "id": "40d8e6577d264471baa3b0875a2a96b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "xs = [0., 1., 2., 3.]\n",
    "loop_exp = [math.exp(t) for t in xs]\n",
    "vec_exp = np.exp(np.array(xs))\n",
    "loop_exp, vec_exp\n"
   ],
   "id": "286ef045c38940a1abc731d26f38585d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0., 0.], [1., 0.], [0., 1.]])\n",
    "diff = X[:, None, :] - X[None, :, :]\n",
    "D = np.sqrt(np.sum(diff**2, axis=-1))\n",
    "D\n"
   ],
   "id": "74aa1c47fa674388bc55ac224aaf4565"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting for intuition: Normal histogram + PDF\n\n",
    "Histogram approximates density; analytic PDF is the reference curve."
   ],
   "id": "0c0cff80127946f789bccd443f21ba73"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create reproducible random numbers or toy data.\n"
   ],
   "id": "55baa0b26eec4734a03a5bfaf5cc8a0d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(7)  # reproducible random generator\n",
    "x = rng.standard_normal(size=50_000).astype(np.float64)  # draw normal samples\n",
    "fig, ax = plt.subplots(figsize=(6.4, 3.2), dpi=140)\n",
    "counts, bins, _ = ax.hist(  # histogram of samples\n",
    "    x, bins=80, density=True, alpha=0.35,  # bins + density\n",
    "    color='C0', label='samples (hist)'\n",
    ")\n",
    "grid = np.linspace(bins[0], bins[-1], 600)\n",
    "pdf = (1.0/np.sqrt(2*np.pi))*np.exp(-0.5*grid*grid)\n",
    "ax.plot(grid, pdf, color='C1', lw=2.0, label='analytic PDF')  # plot element\n",
    "ax.set_xlabel('x')  # set axis/scale\n",
    "ax.set_ylabel('density')  # set axis/scale\n",
    "ax.set_title('Standard Normal: histogram and analytic PDF')  # set axis/scale\n",
    "ax.legend(); ax.grid(alpha=0.25)  # plot element\n",
    "plt.show()  # render figure\n"
   ],
   "id": "3754440b67114a3ca68a5de225bf0ed4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting for intuition: Gaussian surface\n\n",
    "A scalar field z = exp(-(x^2+y^2)) shown as a heatmap."
   ],
   "id": "647a0e763e6c4307847a87a2243820ad"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure Generators (for reproducibility)\n\n",
    "- `code/figures/ch02_sum_error_naive_vs_kahan.py` — rounding error plot.\n",
    "- `code/figures/ch02_normal_hist_pdf.py` — normal histogram + PDF.\n",
    "- `code/figures/ch02_surface_field.py` — Gaussian surface.\n"
   ],
   "id": "8bb51c9aa6d345179ed0e6b5a65e1801"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results to visualize behavior.\n"
   ],
   "id": "491b60c96cb04b96b8cb0ceff6163da4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(-3, 3, 200)\n",
    "ys = np.linspace(-3, 3, 200)\n",
    "Xg, Yg = np.meshgrid(xs, ys)\n",
    "Z = np.exp(-(Xg**2 + Yg**2))\n",
    "fig, ax = plt.subplots(figsize=(6.4, 3.2), dpi=140)\n",
    "im = ax.imshow(  # image of Z\n",
    "    Z, extent=[xs.min(), xs.max(), ys.min(), ys.max()],\n",
    "    origin='lower', cmap='viridis', aspect='auto'\n",
    ")\n",
    "fig.colorbar(im, ax=ax, shrink=0.85)\n",
    "ax.set_xlabel('x'); ax.set_ylabel('y')  # set axis/scale\n",
    "ax.set_title('Gaussian bump: z = exp(-(x^2 + y^2))')  # set axis/scale\n",
    "plt.show()  # render figure\n"
   ],
   "id": "f5564a7549a04228a5c22261fdbb799d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code → Math check: associativity fails in floating-point\n\n",
    "Real addition is associative; rounded addition is not. We expose it numerically."
   ],
   "id": "1c8106bb652e4123b060979350daaf9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = 1e16, 1.0, -1e16\n",
    "(x + y) + z, x + (y + z)\n"
   ],
   "id": "001c13667c76446a9e054446b121104e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://theaiengineer.dev/tae_logo_gw_flat.png' alt='The Python Quants' width='35%' align='right'>\n"
   ],
   "id": "3a26e00e8d9045a783d913e68bd36fac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}