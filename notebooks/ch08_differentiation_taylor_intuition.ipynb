{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://theaiengineer.dev/tae_logo_gw_flat.png' alt='The Python Quants' width='35%' align='right'>\n"
   ],
   "id": "d0248a016cd1447b82799efbe15bf3ab"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python & Mathematics for Data Science and Machine Learning\n",
    "\n",
    "**© Dr. Yves J. Hilpisch | The Python Quants GmbH**<br>\n",
    "AI-powered by GPT-5.x.\n",
    "\n"
   ],
   "id": "6f3a05f7a9ee42cc820da766f9407306"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8 — Differentiation & Taylor Intuition\n\n",
    "This notebook mirrors the chapter: finite differences, gradients, and Taylor approximations with compact checks."
   ],
   "id": "0de1946de30d497c869be492f5d5c1c2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up imports and basic configuration.\n"
   ],
   "id": "829cec888ca04e148efcda5586a084a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np  # numerical arrays and linear algebra\n",
    "import matplotlib.pyplot as plt  # plotting library\n",
    "plt.style.use('seaborn-v0_8')\n"
   ],
   "id": "938232a344a74d3cae94b1e96d094a6a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward vs central difference (1D)"
   ],
   "id": "578e98c2cd49495488e1022c2ffbdd38"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function for clarity.\n"
   ],
   "id": "6a12f4bd2d634fb3be37799ffe8f3f21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): return np.sin(x)  # function f\n",
    "def df(x): return np.cos(x)  # function df\n",
    "x0 = 1.0\n",
    "for h in [1e-1, 1e-2, 1e-3]:\n",
    "    fwd = (f(x0+h)-f(x0))/h\n",
    "    cen = (f(x0+h)-f(x0-h))/(2*h)\n",
    "    print(h, abs(fwd-df(x0)), abs(cen-df(x0)))  # report results\n"
   ],
   "id": "a189a39afe8144f197db5715b423c93c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient via central differences (2D)"
   ],
   "id": "568a366ed3f84bc08feee647a292e3f7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function for clarity.\n"
   ],
   "id": "947f3503c8224837bf20a45fdc58ac15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(xy):  # function g\n",
    "    x,y = xy; return x**2 + 3*x*y + 2*y**2\n",
    "def grad_g(xy):  # function grad_g\n",
    "    x,y = xy; return np.array([2*x + 3*y, 3*x + 4*y], dtype=np.float64)\n",
    "p = np.array([0.7, -0.2])\n",
    "h = 1e-5; ex = np.array([h,0.0]); ey = np.array([0.0,h])\n",
    "dgdx = (g(p+ex)-g(p-ex))/(2*h); dgdy=(g(p+ey)-g(p-ey))/(2*h)\n",
    "print(np.allclose(np.array([dgdx,dgdy]), grad_g(p), atol=1e-6))  # report results\n"
   ],
   "id": "bb9198291517459d82e0e4498cf6fa6f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code → Math checks: directional derivative and Taylor errors"
   ],
   "id": "b6ce451ce8324ba8a7ab1bb967f066be"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a helper function for clarity.\n"
   ],
   "id": "4725f758df1441df94ab2aa01dfb26f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(xy):  # function f2\n",
    "    x,y = xy; return np.exp(x) + x*y + 0.5*y**2\n",
    "def grad_f2(xy):  # function grad_f2\n",
    "    x,y = xy; return np.array([np.exp(x) + y, x + y])\n",
    "x0 = np.array([0.2, -0.3]); u = np.array([1.0, 2.0]); u /= np.linalg.norm(u)\n",
    "h=1e-6; slope_fd = (f2(x0+h*u)-f2(x0-h*u))/(2*h); slope_true=grad_f2(x0).dot(u)\n",
    "ok_dir = np.allclose(slope_fd, slope_true)\n",
    "# Taylor errors (1st vs 2nd) for exp at x0\n",
    "def f1(x): return np.exp(x)  # function f1\n",
    "def df1(x): return np.exp(x)  # function df1\n",
    "def d2f1(x): return np.exp(x)  # function d2f1\n",
    "x0s = [0.0, 0.5]; h=0.1\n",
    "ratios=[]\n",
    "for x0 in x0s:\n",
    "    f0=f1(x0); t1=f0+df1(x0)*h; t2=f0+df1(x0)*h+0.5*d2f1(x0)*h**2\n",
    "    err1=abs(f1(x0+h)-t1); err2=abs(f1(x0+h)-t2); ratios.append(err1/err2)\n",
    "ok_dir, np.round(ratios,1)\n"
   ],
   "id": "46f68a3d5ced473a818cbe29282008b8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure Generators (for reproducibility)\n\n",
    "- `code/figures/ch08_tangent_line.py` — tangent line.\n",
    "- `code/figures/ch08_taylor_orders.py` — Taylor orders 1 vs 2.\n"
   ],
   "id": "85bb1f792a0a4478b878a18c99cf21d8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cubic remainder vs quadratic model scaling (1D)\n",
    "import numpy as np\n",
    "\n",
    "def f(x):\n",
    "    return x**3 - 2*x**2 + x\n",
    "\n",
    "def df(x):\n",
    "    return 3*x**2 - 4*x + 1\n",
    "\n",
    "def d2f(x):\n",
    "    return 6*x - 4\n",
    "\n",
    "x0 = 0.7\n",
    "hs = np.array([1e-1, 5e-2, 2.5e-2])\n",
    "# Second-order Taylor around x0 for these h (vectorized)\n",
    "t2 = f(x0) + df(x0)*hs + 0.5*d2f(x0)*(hs**2)\n",
    "# Remainder r3 ~ O(h^3)\n",
    "r3 = f(x0 + hs) - t2\n",
    "# Ratio r3 / (0.5 f''(x0) h^2) ~ O(h) -> 0\n",
    "ratios = r3 / (0.5*d2f(x0)*hs**2)\n",
    "np.round(ratios, 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualize function vs second-order Taylor around x0 for several h\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x0 = 0.7\n",
    "hs = [0.1, 0.05]\n",
    "\n",
    "# Define cubic and its derivatives\n",
    "f = lambda x: x**3 - 2*x**2 + x\n",
    "fp = lambda x: 3*x**2 - 4*x + 1\n",
    "fpp = lambda x: 6*x - 4\n",
    "\n",
    "xs = np.linspace(x0-0.2, x0+0.2, 400)\n",
    "fx = f(xs)\n",
    "\n",
    "fig, ax = plt.subplots(1, len(hs), figsize=(9, 3.4), dpi=140, sharey=True)\n",
    "for j,h in enumerate(hs):\n",
    "    axj = ax[j] if len(hs)>1 else ax\n",
    "    # second-order Taylor polynomial about x0, evaluated on xs\n",
    "    t2_xs = f(x0) + fp(x0)*(xs-x0) + 0.5*fpp(x0)*(xs-x0)**2\n",
    "    axj.plot(xs, fx, label='f(x)', color='C0')\n",
    "    axj.plot(xs, t2_xs, label='T2 at x0', color='C1', ls='--')\n",
    "    axj.axvline(x0, color='k', lw=0.8, ls=':')\n",
    "    axj.set_title(f'h = {h}')\n",
    "    axj.grid(alpha=0.25)\n",
    "    if j==0:\n",
    "        axj.set_ylabel('value')\n",
    "    axj.set_xlabel('x')\n",
    "\n",
    "handles, labels = ax[0].get_legend_handles_labels() if isinstance(ax, np.ndarray) else ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "fig.tight_layout(rect=(0,0.12,1,1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://theaiengineer.dev/tae_logo_gw_flat.png' alt='The Python Quants' width='35%' align='right'>\n"
   ],
   "id": "82eefb58b9a64234a293bcac73611dc7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}